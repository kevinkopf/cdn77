user www-data;
worker_processes auto;
pid /run/nginx.pid;
include /etc/nginx/modules-enabled/*.conf;

events {
	worker_connections 768;
	# multi_accept on;
}

http {
  upstream backend {
    # We recommend setting the parameter to twice the number of servers listed in the upstream{} block.
    # This is large enough for NGINX to maintain keepalive connections with all the servers,
    # but small enough that upstream servers can process new incoming connections as well.
    # https://www.nginx.com/blog/avoiding-top-10-nginx-configuration-mistakes/#no-keepalives
    keepalive 4;
    server {{ nginx_host }};
  }

  proxy_cache_path  /usr/share/nginx/cache  levels=1:2    keys_zone=STATIC:10m
  inactive=24h  max_size=1g;
  server {
    listen 80;
    return 301 https://$host$request_uri;
  }
  server {
    listen          443 ssl;

    ssl_certificate        /etc/nginx/localhost.crt;
    ssl_certificate_key    /etc/nginx/localhost.key;
    ssl_protocols          TLSv1.2 TLSv1.3;
    ssl_ciphers            'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384';


    location / {
      proxy_pass             http://backend;
      proxy_set_header       Host $host;
      proxy_buffering        on;
      proxy_cache            STATIC;
      proxy_cache_valid      200  1d;
      proxy_cache_use_stale  error timeout invalid_header updating
                             http_500 http_502 http_503 http_504;
      proxy_http_version     1.1;
      proxy_set_header       Connection "";
    }

    location /metrics {
      content_by_lua_block {
        local handler = assert(io.popen("/usr/local/bin/generate.sh", 'r'))
        local data = assert(handler:read('*a'))
        handler:close()
        ngx.print(data)
      }
    }
  }
}